{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c43943",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c10dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf==4.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37682f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "#import simplejson\n",
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "#from PIL import Image\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import base64\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn import preprocessing\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sortedcontainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = int(datetime.today().strftime('%Y%m%d'))\n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24596093",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset_columns = ['id', 'document_vector', 'ipc_tech_field', 'ind_claims_count', 'bwd_citations_count', 'drawings_count', 'avg_claim_sim_bwd_citations', 'ipc_values_count', 'org_prior_citations_count', 'fwd_citation_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622fb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector(title = \"\", abstract = \"\", independent_claims = []):\n",
    "    '''\n",
    "    title: str\n",
    "    abstract: str\n",
    "    independent_claims: [str1, str2]\n",
    "    \n",
    "    returns the JSON response with a 384-dimensional vector\n",
    "    '''\n",
    "    url_and_query = \"http://10.1.0.230:5000/embed_document\"\n",
    "    jsonData = {'title': title,\n",
    "               'abstract': abstract,\n",
    "               'independent_claims': independent_claims}\n",
    "    #print(url_and_query)\n",
    "\n",
    "    try:\n",
    "        r = requests.post(url_and_query, json = jsonData)\n",
    "        r.raise_for_status()\n",
    "    except:\n",
    "        print(r)\n",
    "    response = r.json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44824100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_tags(xml_string: str) -> str:\n",
    "    \n",
    "    blockOrBrElement = set([\"br\", \"address\", \"article\", \"aside\", \"blockquote\", \"canvas\", \"dd\", \"div\", \"dl\", \"dt\", \"fieldset\", \"figcaption\", \"figure\", \"footer\", \"form\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"header\", \"hr\", \"li\", \"main\", \"nav\", \"noscript\", \"ol\", \"p\", \"pre\", \"section\", \"table\", \"tfoot\", \"ul\", \"video\"])\n",
    "    parser = ET.XMLPullParser(['start', 'end'])\n",
    "    parser.feed(xml_string)\n",
    "    output = []\n",
    "    isIndependent = True\n",
    "    firstClaim = []\n",
    "    isFirstClaim = True\n",
    "    for event, elem in parser.read_events():\n",
    "        if event == 'start':\n",
    "            if elem.tag == 'x-claim':\n",
    "                #print(elem.attrib['independent'])\n",
    "                if elem.attrib.get('independent', \" \") == \"yes\":\n",
    "                    isIndependent = True\n",
    "                else:\n",
    "                    isIndependent = False\n",
    "                if \"first\" not in elem.attrib:\n",
    "                    isFirstClaim = False\n",
    "            text = elem.text\n",
    "            if text != None and isIndependent == True:\n",
    "                output.append(elem.text)\n",
    "                if isFirstClaim == True:\n",
    "                    firstClaim.append(elem.text)\n",
    "\n",
    "        elif event == 'end':\n",
    "            if elem.tag in blockOrBrElement:\n",
    "                output.append('')\n",
    "                if isFirstClaim==True:\n",
    "                    firstClaim.append('')\n",
    "\n",
    "            tailText = elem.tail\n",
    "            if tailText != None and isIndependent == True:\n",
    "                #e.g. <a>some<b>stuff</b>blah</a>, blah will be the tail text of the <b>\n",
    "                output.append(tailText)\n",
    "                if isFirstClaim==True:\n",
    "                    firstClaim.append(tailText)\n",
    "    return ''.join(output), ''.join(firstClaim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e9b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_vector(claim: str):\n",
    "    '''\n",
    "    claim: str\n",
    "    \n",
    "    returns the JSON response with a 384-dimensional vector\n",
    "    '''\n",
    "    url_and_query = \"http://10.1.0.230:5000/embed_query\"\n",
    "    jsonData = {'query': claim,\n",
    "               \"auto_translate\": True}\n",
    "    #print(url_and_query)\n",
    "\n",
    "    try:\n",
    "        r = requests.post(url_and_query, json = jsonData)\n",
    "        r.raise_for_status()\n",
    "    except:    \n",
    "        print(\"claim_vector\", r)\n",
    "    response = r.json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9cfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_docs(input_doc_vector, earliest_priority_date):\n",
    "    #new model\n",
    "    url_and_query = \"http://10.1.0.49:8984/solr/ifidev_newvector/select\"\n",
    "    payload = {\"q\": \"{!knn f=tiabindclvector topK=5}\" + str(input_doc_vector['vector'])}\n",
    "    #print(url_and_query)\n",
    "\n",
    "    r = requests.post(url_and_query, data=payload)\n",
    "    r.raise_for_status()\n",
    "    #print(\"top_5_docs\", r)\n",
    "    response = r.json()\n",
    "    \n",
    "    documents = response[\"response\"][\"docs\"]\n",
    "    patents = []\n",
    "    for doc in documents:\n",
    "        #print(doc)\n",
    "        patent = doc[\"id\"]\n",
    "        country = doc[\"country\"]\n",
    "        #print(\"\\n\\ncountry:\", country)\n",
    "        date = str(doc[\"earliestprioritydate\"])\n",
    "        date_object = datetime.strptime(date, \"%Y%m%d\").date()\n",
    "        earliest_priority_date_object = datetime.strptime(earliest_priority_date, \"%Y%m%d\").date()\n",
    "        if date_object < earliest_priority_date_object and country == \"US\":\n",
    "            patents.append(patent)\n",
    "    return patents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919f3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bwd_citation_data(patents):\n",
    "    DATA_ENDPOINT = r\"http://10.0.1.106:8983/solr/ificlaims/pbsearch\"\n",
    "    url = f\"{DATA_ENDPOINT}?q=pn=(\"\n",
    "    fls = \"id,titles,claims,abstracts\" #\"id,abstracts,abstracts_mt,claims,claims_mt\"\n",
    "    #hasRej101, hasRej102, hasRej103, hasRej112\n",
    "    i=0\n",
    "    for patent in patents:\n",
    "        url += f\"{patent}%20or%20\"\n",
    "    url = f\"{url[:-8]})&fl={fls}\"\n",
    "    url_text = url\n",
    "    #print(url_text)\n",
    "    r_text = requests.get(url_text, timeout=36000)\n",
    "    r_text.raise_for_status()\n",
    "    response_text = r_text.json()\n",
    "\n",
    "    final_dataset = pd.DataFrame(columns= ['id', 'title', 'abstract', 'independent_claims'])\n",
    "    docs = response_text[\"response\"][\"docs\"]\n",
    "    for doc in docs:\n",
    "        claims = doc.get(\"claims\", \" \")\n",
    "        claims_text = []\n",
    "        for claim in claims:\n",
    "            claim_text, doc_first_claim = strip_tags(claim)\n",
    "            claims_text.append(claim_text)\n",
    "        doc_all_claims = [''.join(claims_text)]\n",
    "        doc_id = doc.get(\"id\", \" \")\n",
    "        doc_abstract, _ = strip_tags(doc.get(\"abstracts\", \" \")[0])\n",
    "        doc_title = strip_tags(doc.get(\"titles\", \" \")[0])\n",
    "        row = pd.DataFrame([[doc_id, doc_title[0], doc_abstract, doc_all_claims]], columns= ['id', 'title', 'abstract', 'independent_claims'])\n",
    "        final_dataset = pd.concat([final_dataset, row], ignore_index=True)\n",
    "    #print(\"final_dataset:\", final_dataset)\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e929aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(vector1, vector2):\n",
    "    #print(vector1.shape)\n",
    "    #print(vector2.shape)\n",
    "    cosine = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "    return cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3865228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_similarity(input_document_vector, patents):\n",
    "    patent_vectors = []\n",
    "    \n",
    "    if len(input_document_vector)==0:\n",
    "        return 0\n",
    "    #get title, abstract, and claims\n",
    "    #print(\"older patent ids:\", patents)\n",
    "    older_patents = get_bwd_citation_data(patents)\n",
    "    doc_similarity_scores = []\n",
    "    for index, row in older_patents.iterrows():\n",
    "        older_doc_vector = get_doc_vector(row['title'], row['abstract'], row['independent_claims'])\n",
    "        older_doc_vector = older_doc_vector.get('vector', [])\n",
    "        if len(older_doc_vector)==0:\n",
    "            continue\n",
    "        #print(\"input vector:\", input_document_vector)\n",
    "        #print(\"older doc vector:\", torch.tensor(older_doc_vector['vector']))\n",
    "        doc_similarity_scores.append(get_similarity(input_document_vector, torch.tensor(older_doc_vector)))\n",
    "    \n",
    "    #print(doc_similarity_scores)\n",
    "    doc_similarity_scores_list = [t.numpy().item() for t in doc_similarity_scores]\n",
    "    #print(doc_similarity_scores_list)\n",
    "    if len(doc_similarity_scores_list) > 0:\n",
    "        return mean(doc_similarity_scores_list)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6778df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Collection, Set\n",
    "from sortedcontainers import SortedSet  # Using SortedSet for ordered sets\n",
    "\n",
    "class TechnologyClassifier:\n",
    "    first_four_chars_to_sector = {}\n",
    "    before_slash_to_sector = {}\n",
    "\n",
    "    @classmethod\n",
    "    def __init__(cls):\n",
    "        # These definitions come from https://www.wipo.int/export/sites/www/ipstats/en/statistics/patents/xls/ipc_technology.xls\n",
    "        ipc_first_four_chars = re.compile(r\"([A-Z]\\d{2}[A-Z])%\")\n",
    "        ipc_before_slash = re.compile(r\"([A-Z]\\d{2}[A-Z])\\s*([1-9]\\d*)/?%\")\n",
    "\n",
    "        with open('ipc_technology.tsv', 'r', encoding='utf-8') as reader:\n",
    "            for line in reader:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) != 3:\n",
    "                    raise ValueError(\"Invalid line in technologies definition file: \" + line)\n",
    "\n",
    "                sector, field, code = map(str.strip, parts)\n",
    "                m = ipc_first_four_chars.match(code)\n",
    "                if m:\n",
    "                    cls.first_four_chars_to_sector[m.group(1)] = [sector, field]\n",
    "                else:\n",
    "                    m = ipc_before_slash.match(code)\n",
    "                    if m:\n",
    "                        cls.before_slash_to_sector[m.group(1) + m.group(2)] = [sector, field]\n",
    "                    else:\n",
    "                        raise ValueError(\"Unexpected IPC code in technologies definition file: \" + line)\n",
    "\n",
    "    @classmethod\n",
    "    def classify(cls, ipc_codes_first_four_chars: Collection[str], ipc_before_slash: Collection[str]):\n",
    "        sectors = SortedSet()\n",
    "        fields = SortedSet()\n",
    "\n",
    "        for sub_code in ipc_codes_first_four_chars:\n",
    "            sector_field = cls.first_four_chars_to_sector.get(sub_code)\n",
    "            if sector_field:\n",
    "                sectors.add(sector_field[0])\n",
    "                fields.add(sector_field[1])\n",
    "\n",
    "        for sub_code in ipc_before_slash:\n",
    "            sector_field = cls.before_slash_to_sector.get(sub_code)\n",
    "            if sector_field:\n",
    "                sectors.add(sector_field[0])\n",
    "                fields.add(sector_field[1])\n",
    "\n",
    "        return TechnologyClassifierResult(sectors, fields)\n",
    "\n",
    "\n",
    "class TechnologyClassifierResult:\n",
    "    def __init__(self, sectors: Set[str], fields: Set[str]):\n",
    "        self.sectors = sectors\n",
    "        self.fields = fields\n",
    "\n",
    "tech_classifier = TechnologyClassifier()\n",
    "result = tech_classifier.classify([\"A01B\", \"C07D\"], [\"A01B12\", \"C07D100\"])\n",
    "\n",
    "print(\"Sectors:\", result.sectors)\n",
    "print(\"Fields:\", result.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb043ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextCursorMark = \"AoEuQ04tMTAyMjg3OTcwLUE=\"\n",
    "url_and_query = \"http://solrifi.patdocs.com:8981/solrbackup/ificlaims/pbsearch?q=fam=(pdus=2019 and grant=us and design=false and plant=false) and nctb > 0 and nctf >0&fl=id, grantucid, titles, claims, abstracts, mainipcvalues, assignees_name, independentclaimscount, expectedexpirydate, ipctechnologyfield, usapplicationstatus, ipcrvalues, backwardcitations:[json], backwardcitationscount, drawingscount, forwardcitationscount,forwardcitations:[json]&fq={!collapse field=simplefamily}&expand=true&sort=id asc&rows=100&cursorMark=\" + nextCursorMark\n",
    "query_fwd = \"http://solrifi.patdocs.com:8981/solrbackup/ificlaims/pbsearch?q=ctf=(pn=CN-108424449-A)&fq={!collapse field=applicationnumber}&sort=id asc&cursorMark=\" + nextCursorMark\n",
    "try:\n",
    "    r = requests.get(url_and_query, timeout=36000)\n",
    "    r.raise_for_status()\n",
    "except:\n",
    "    print(\"overall query\", r)\n",
    "response = r.json()\n",
    "#print(response)\n",
    "\n",
    "documents = response[\"response\"][\"docs\"]\n",
    "nextCursorMark = response[\"nextCursorMark\"]\n",
    "print(\"start\")\n",
    "for doc in documents:\n",
    "    claims = doc.get(\"claims\", \" \")\n",
    "    claims_text = []\n",
    "    for claim in claims:\n",
    "        claim_text, doc_first_claim = strip_tags(claim)\n",
    "        claims_text.append(claim_text)\n",
    "    doc_all_claims = [''.join(claims_text)]\n",
    "\n",
    "    #claim count - independentclaimscount - done\n",
    "    #number of ipcr values\n",
    "    #drawing count\n",
    "    #number of backward citations\n",
    "    #org/inventor log of past fwd citations\n",
    "    #Patent similarity with backward citations\n",
    "    #LDA Topic Models as a Classification Model Input\n",
    "\n",
    "    doc_id = doc.get(\"id\", \" \")\n",
    "    doc_abstract, _ = strip_tags(doc.get(\"abstracts\", \" \")[0])\n",
    "    doc_title = strip_tags(doc.get(\"titles\", \" \")[0])[0]\n",
    "    doc_ipctechnologyfield = doc.get(\"ipctechnologyfield\", \" \")\n",
    "    doc_forwardcitations = doc.get(\"forwardcitations\", [])\n",
    "    doc_ipc = doc.get(\"mainipcvalues\", \" \")\n",
    "    doc_grantucid = doc.get(\"grantucid\", \" \")\n",
    "    slash_index = doc_ipc.find(\"/\")\n",
    "\n",
    "    doc_indclaimscount = doc.get(\"independentclaimscount\", \" \")\n",
    "    doc_drawingscount = doc.get(\"drawingscount\", 0)\n",
    "    doc_bwdcitationscount = doc.get(\"backwardcitationscount\", 0)\n",
    "    doc_ipcrvalues = doc.get(\"ipcrvalues\", [])\n",
    "    doc_ipcrvaluescount = len(doc_ipcrvalues)\n",
    "\n",
    "    doc_organization_names = doc.get(\"assignees_name\", [])\n",
    "\n",
    "    doc_org_citations_count = 0\n",
    "    #http://solrifi.patdocs.com:8981/solrbackup/ificlaims/pbsearch?q=CTF=(pa=FAIRTECH%20INVESTMENT%20LTD)%20AND%20PD=NOW-5y:NOW&fq={!collapse%20field=applicationnumber}&rows=0\n",
    "    for org in doc_organization_names:\n",
    "        try:\n",
    "            query = \"http://solrifi.patdocs.com:8981/solrbackup/ificlaims/pbsearch?q=CTF=(pa=\" + org + \") AND PD=NOW-5y:NOW&fq={!collapse field=applicationnumber}&rows=0\"\n",
    "            r1 = requests.get(url_and_query, timeout=36000)\n",
    "            r1.raise_for_status()\n",
    "        except:\n",
    "            print(\"org cit count\", r1)\n",
    "        response1 = r1.json()\n",
    "        doc_org_citations_count += int(response1[\"response\"].get(\"numFound\", 0))\n",
    "        time.sleep(1)\n",
    "        #print(org, doc_org_citations_count)\n",
    "\n",
    "    #print(\"prior org nctf\", doc_org_citations_count)\n",
    "    bwdcitations = doc.get(\"backwardcitations\", [])\n",
    "    bwdcitation_ucids = []\n",
    "    if len(bwdcitations) > 0:\n",
    "        for d in bwdcitations:\n",
    "            b_ucid = d.get(\"ucid\", \"\")\n",
    "            if b_ucid is not None and len(b_ucid)>0:\n",
    "                bwdcitation_ucids.append(b_ucid)           \n",
    "\n",
    "    if slash_index == -1:\n",
    "        continue\n",
    "    result = tech_classifier.classify([doc_ipc[:4]], [doc_ipc[:slash_index]])\n",
    "    if len(result.fields) == 0:\n",
    "        continue\n",
    "    doc_ipctechnologyfield = result.fields[0]\n",
    "    doc_forwardcitationscount = doc.get(\"forwardcitationscount\", 0)\n",
    "\n",
    "    #if doc_bwdcitationscount==0: #or doc_forwardcitationscount==0:\n",
    "        #continue\n",
    "    \n",
    "    doc_vector = get_doc_vector(title= doc_title, abstract= doc_abstract, independent_claims= doc_all_claims)\n",
    "\n",
    "    doc_avgclaimsimilaritybwdcitations = 0\n",
    "    #print(bwdcitations)\n",
    "    #print(bwdcitation_ucids)\n",
    "    if len(bwdcitation_ucids)>0:\n",
    "        doc_avgclaimsimilaritybwdcitations = get_document_similarity(torch.tensor(doc_vector.get('vector', [])), bwdcitation_ucids)\n",
    "\n",
    "    #print(\"sim:\", doc_avgclaimsimilaritybwdcitations)\n",
    "\n",
    "    doc_numipcvalues = len(doc_ipc)\n",
    "    if doc_grantucid == \" \" or doc_ipc == \" \":\n",
    "        continue\n",
    "    row = pd.DataFrame([[doc_id, [doc_vector], doc_ipctechnologyfield, doc_indclaimscount, \n",
    "                         doc_bwdcitationscount, doc_drawingscount, doc_avgclaimsimilaritybwdcitations,\n",
    "                         doc_ipcrvaluescount, doc_org_citations_count, doc_forwardcitationscount]], columns= final_dataset_columns)\n",
    "    #print(row)\n",
    "    #['id', 'document_vector', 'ipc_tech_field', 'ind_claims_count', 'bwd_citations_count', \n",
    "    # 'drawings_count', 'avg_claim_sim_bwd_citations', 'ipc_values_count', 'org_prior_citations_count', 'fwd_citation_count']\n",
    "    final_dataset = pd.concat([final_dataset, row], ignore_index=True)\n",
    "print(\"\\nfinal dataset:\", final_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8056c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nextCursorMark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0839d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nextCursorMark)\n",
    "final_dataset.to_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = final_dataset['ipc_tech_field'].unique()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_tech_field = {}\n",
    "for tech_field in a:\n",
    "    v = get_claim_vector(tech_field)\n",
    "    ipc_tech_field[tech_field] = v['vector']\n",
    "print(ipc_tech_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tech_field_vector(tech_field):\n",
    "    return ipc_tech_field[tech_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['ipc_tech_field_vector'] = final_dataset['ipc_tech_field'].apply(get_tech_field_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.drop(['document_vector'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero1 = pd.read_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_0_1.csv')\n",
    "zero2 = pd.read_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_0_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [zero1, zero2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071303f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerodf = pd.concat(zero, ignore_index=True)\n",
    "print(zerodf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerodf = zerodf.drop(['Unnamed: 0'], axis=1)\n",
    "print(zerodf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c51d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset=zero1\n",
    "final_dataset = final_dataset.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.read_csv(\"/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_no_NA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f44131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(entry):\n",
    "    element = literal_eval(entry)\n",
    "    return element[0].get(\"vector\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset['document_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce14ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['doc_vector'] = final_dataset['document_vector'].apply(get_vector)\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac07605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset['doc_vector'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['ipc_tech_field_vector'] = final_dataset['ipc_tech_field'].apply(get_tech_field_vector)\n",
    "print(final_dataset['ipc_tech_field_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4182f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_df = final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abaf9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_no_NA.csv', converters={'doc_vector': pd.eval, 'ipc_tech_field_vector': pd.eval})\n",
    "#print(full_dataset.info())\n",
    "#print(full_dataset.loc[full_dataset['doc_vector'] == 0])\n",
    "#print(full_dataset.loc[full_dataset['ipc_tech_field_vector'] == 0])\n",
    "#full_dataset = full_dataset[full_dataset.doc_vector != 0]\n",
    "#full_dataset = full_dataset[full_dataset.ipc_tech_field_vector != 0]\n",
    "#print(full_dataset.loc[full_dataset['doc_vector'] == 0])\n",
    "#print(full_dataset.loc[full_dataset['ipc_tech_field_vector'] == 0])\n",
    "X = full_dataset.drop(['id', 'ipc_tech_field', 'fwd_citation_count'], axis=1)\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40433aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_dataset['fwd_citation_count'].values\n",
    "y_transform = []\n",
    "for cit in y:\n",
    "    cit_transform = math.log1p(cit)#cit**(1/3)#\n",
    "    y_transform.append(cit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_df.describe(), zero_df.columns)\n",
    "print(final_dataset.describe(), zero_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97134364",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_df = zero_df.drop(['document_vector', 'patent_age'], axis=1)\n",
    "final_dataset = final_dataset.drop(['Unnamed: 0', 'document_vector', 'patent_age', 'ipc_tech_field_vector'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [final_dataset, zero_df]\n",
    "X = pd.concat(X, ignore_index=True)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6168dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(X['ipc_tech_field'].unique())\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "enc_df = pd.DataFrame(encoder.fit_transform(X[['ipc_tech_field']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_df)\n",
    "print(len(X['ipc_tech_field'].unique()))\n",
    "enc_df[\"combined\"] = enc_df.apply(pd.Series.tolist,axis=1)\n",
    "print(enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3aa525",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df['combined'] = enc_df['combined'].apply(lambda x: np.array(x))\n",
    "print(enc_df['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8378237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ipc_tech_field_one_hot'] = enc_df['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate doc vector and ipc tech field vector\n",
    "'''\n",
    "X['doc_techfield'] = X.apply(lambda row: np.divide(np.add(np.array(row['doc_vector']).flatten(), np.array(row['ipc_tech_field_vector']).flatten()), 2), axis=1)\n",
    "#print(X['avg_vector'])\n",
    "arr_X_avg_vector = []#numpy.zeros((103806, 769))\n",
    "i = 0\n",
    "for item in X['avg_vector']:\n",
    "    arr_X_avg_vector.append(list(item))\n",
    "    #print(arr_X_avg_vector[i])\n",
    "    i+=1\n",
    "X_avg_vector = np.array(arr_X_avg_vector)\n",
    "print(X_avg_vector.shape)\n",
    "#l2 normalize X_avg_vector\n",
    "X_avg_vector_norm = preprocessing.normalize(X_avg_vector, norm='l2')\n",
    "print(X_avg_vector_norm.shape)\n",
    "'''\n",
    "\n",
    "X['doc_techfield'] = X.apply(lambda row: np.concatenate((np.array(row['doc_vector']).flatten(), np.array(row['ipc_tech_field_one_hot']).flatten())), axis=1)\n",
    "#print(X['concat'])\n",
    "arr_X_concat = []\n",
    "i = 0\n",
    "for item in X['doc_techfield']:\n",
    "    arr_X_concat.append(list(item))\n",
    "    #print(arr_X_concat[i])\n",
    "    i+=1\n",
    "X_concat = np.array(arr_X_concat)\n",
    "#l2 normalize X_concat\n",
    "X_concat_norm = preprocessing.normalize(X_concat, norm='l2')\n",
    "print(X_concat.shape)\n",
    "X['doc_techfield'] = pd.Series(X_concat_norm.tolist()).to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89509fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X['doc_techfield'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['concat1'] = X.apply(lambda row: np.concatenate((np.array(row['patent_age']).flatten(), np.array(row['doc_vector']).flatten())), axis=1)\n",
    "#print(X['concat'])\n",
    "arr_X_concat = []\n",
    "i = 0\n",
    "for item in X['concat1']:\n",
    "    arr_X_concat.append(list(item))\n",
    "    #print(arr_X_concat[i])\n",
    "    i+=1\n",
    "X_concat1 = np.array(arr_X_concat)\n",
    "#l2 normalize X_concat\n",
    "X_concat_norm1 = preprocessing.normalize(X_concat, norm='l2')\n",
    "print(X_concat1.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concat_norm1, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_concat_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3775a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.Series(X_avg_vector_norm.tolist()).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat,doc_vector,fwd_citation_count,fwd_citation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49833cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['doc_vector'] = final_dataset['doc_vector']\n",
    "new_df['fwd_citation_count'] = final_dataset['fwd_citation_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691706c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns = ['doc_ipc_vector_avg', 'doc_vector', 'fwd_citation_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X['ipc_tech_field_one_hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count = X['fwd_citation_count'].values\n",
    "y_class = []\n",
    "for v in y_count:\n",
    "    v_class = 0\n",
    "    if v == 0:\n",
    "        v_class = 1\n",
    "    elif 0<v<=3:\n",
    "        v_class = 2\n",
    "    elif 3<v<=10:\n",
    "        v_class = 3\n",
    "    elif 10<v<=100:\n",
    "        v_class = 4\n",
    "    elif 100<v:#<=500:\n",
    "        v_class = 5\n",
    "    #elif 500<v<=1000:\n",
    "       #v_class = 6\n",
    "    #elif v>1000:\n",
    "        #v_class = 7\n",
    "\n",
    "    y_class.append(v_class)\n",
    "print(y_class)\n",
    "X['fwd_citation_class']=pd.Series(y_class)\n",
    "print(X['fwd_citation_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_class_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ab845",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_zero_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228635a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = [full_zero_df, new_df]\n",
    "print(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_processed_dataset = pd.concat(full_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ecd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf88bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_processed_dataset.to_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_class_full_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval \n",
    "processed_df = pd.read_csv('/home/skalsi@minesoft.local/predict-fwd-citation/fwd_citations_processed_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c917c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[\"concat\"] = processed_df[\"concat\"].apply(lambda x: literal_eval(x))\n",
    "processed_df[\"concat\"] = processed_df[\"concat\"].apply(lambda x: np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = processed_df[\"concat\"].to_numpy()\n",
    "X_concat = np.vstack(X_concat)\n",
    "print(X_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = processed_df[\"fwd_citation_count\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b581fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without patent age\n",
    "X_new = X.drop(['patent_age'], axis=1)\n",
    "X_new['flat_feature'] = X_new.apply(lambda row: np.concatenate((np.array(row['doc_vector']).flatten(), np.array(row['ipc_tech_field_vector']).flatten())), axis=1)\n",
    "print(X_new['flat_feature'])\n",
    "\n",
    "arr_X_flat_feature = []#numpy.zeros((103806, 769))\n",
    "i = 0\n",
    "for item in X_new['flat_feature']:\n",
    "    arr_X_flat_feature.append(list(item))\n",
    "    print(arr_X_flat_feature[i])\n",
    "    i+=1\n",
    "X_new_flat_feature = np.array(arr_X_flat_feature)\n",
    "print(X_new_flat_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc140ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y))\n",
    "print(np.std(y))\n",
    "print(np.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y, columns =['fwd_citation_count'])\n",
    "sns.displot(y_df, x = \"fwd_citation_count\")#.set_title(\"Distribution of forward citation counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf08edb",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb79680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap dim reduction\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=3)\n",
    "embedding = tsne.fit_transform(X_only_vector)\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embedding, y_train, s=10, color='blue')\n",
    "plt.title('2D Plot of y vs. X', fontsize=16)\n",
    "plt.xlabel('X', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ec277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points\n",
    "ax.scatter(embedding[:, 0], embedding[:, 1], y_train, c=y_train, cmap='viridis')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Vector Dimension 1', fontsize=12)\n",
    "ax.set_ylabel('Vector Dimension 2', fontsize=12)\n",
    "ax.set_zlabel('Dependent Variable', fontsize=12)\n",
    "ax.set_title('3D Plot with Vector Data and Dependent Variable', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train[0], y_train)\n",
    "predictions = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(mse**0.5)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "#X_train=X_train.drop(['index'],axis=1)\n",
    "#y_train=y_train.drop(['index'],axis=1)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "model = xgb.XGBRegressor(eval_metric = \"rmsle\")\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "mse_xg = mean_squared_error(y_test, predictions)\n",
    "print(mse_xg**0.5)\n",
    "r2 = r2_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0af09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "#hyperparameter distributions\n",
    "param_dist = {\n",
    "    'max_depth': stats.randint(3, 10),\n",
    "    'eta': stats.uniform(0.01, 0.1),\n",
    "    'subsample': stats.uniform(0.5, 0.5),\n",
    "    'n_estimators':stats.randint(50, 200)\n",
    "}\n",
    "\n",
    "# XGBoost model object\n",
    "xgb_model = xgb.XGBRegressor(eval_metric = \"rmsle\")\n",
    "#grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=10, cv=5)\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c816da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = xgb.XGBRegressor(learning_rate = random_search.best_params_[\"eta\"],\n",
    "                        max_depth  = random_search.best_params_[\"max_depth\"],\n",
    "                        subsample = random_search.best_params_[\"subsample\"],\n",
    "                        n_estimators = random_search.best_params_[\"n_estimators\"])\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "pr = []\n",
    "for p in predictions:\n",
    "    if p<0:\n",
    "        p = 0\n",
    "    pr.append(p)\n",
    "\n",
    "predictions = np.array(pr)\n",
    "mse_xg = mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(mse_xg**0.5)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(r2)\n",
    "\n",
    "rmsle = (mean_squared_log_error(y_test, predictions))**0.5\n",
    "print(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfef2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "idx = [ i for i in range(10381)]\n",
    "plt.plot(idx, y_test, color='blue', label='Actual')\n",
    "plt.plot(idx, predictions, color='red', label='Predicted')\n",
    "plt.title('XG Boost Regression')\n",
    "plt.xlabel('Input feature')\n",
    "plt.ylabel('Target variable')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_dataset['fwd_citation_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17156c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_test))\n",
    "print(np.std(y_test))\n",
    "print(np.var(y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(np.mean(predictions))\n",
    "print(np.std(predictions))\n",
    "print(np.var(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['price_log1p']).set_title(\"Distribution of log(1 + price)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31955067",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_regressor = SVR(kernel='poly', C=10, gamma='scale')  #RBF kernel for non-linear regression\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "predictions = svm_regressor.predict(X_test)\n",
    "\n",
    "#Calculate Mean Squared Error (MSE) as a performance metric\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c60080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R-squared value\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared svm regressor\", r2)\n",
    "\n",
    "print(\"Root Mean Squared Error:\", mse**0.5)\n",
    "\n",
    "print(np.mean(y_test))\n",
    "print(np.std(y_test))\n",
    "print(np.var(y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(np.mean(predictions))\n",
    "print(np.std(predictions))\n",
    "print(np.var(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4683b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0eded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(SVR(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "predictions = grid.predict(X_test)\n",
    "#Calculate Mean Squared Error (MSE) as a performance metric\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Root Mean Squared Error:\", mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa338f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared value\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared svm regressor\", r2)\n",
    "\n",
    "# Plot the results\n",
    "idx = [ i for i in range(31142)]\n",
    "plt.scatter(idx, y_test, color='blue', label='Actual')\n",
    "plt.scatter(idx, predictions, color='red', label='Predicted')\n",
    "plt.title('Support Vector Machine (SVM) Regression')\n",
    "plt.xlabel('Input feature')\n",
    "plt.ylabel('Target variable')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Artificial Neural Network\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "train = X_train\n",
    "target = np.array(y_train)\n",
    "test = X_test\n",
    "NN_model = tf.keras.Sequential()\n",
    "#NN_model.add(tf.keras.layers.Dense(64, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "#NN_model.add(tf.keras.layers.Dropout(0.25))\n",
    "#NN_model.add(tf.keras.layers.Dense(256, kernel_initializer='normal', input_dim = train.shape[1], activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dropout(0.5, input_dim = train.shape[1]))\n",
    "NN_model.add(tf.keras.layers.Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dropout(0.5))\n",
    "NN_model.add(tf.keras.layers.Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dense(8, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dropout(0.5))\n",
    "NN_model.add(tf.keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "NN_model.compile(loss='mean_squared_error', optimizer=Adam(lr=1e-3), metrics=['mean_squared_error'])\n",
    "print(NN_model.summary())\n",
    "\n",
    "checkpoint_name = 'Weights-0.5-256-128-0.5-32-8-0.5-1-mse-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint, es]\n",
    "history = NN_model.fit(train, target, epochs=1000, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n",
    "print(history)\n",
    "print(NN_model)\n",
    "predictions = NN_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df522c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3391ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbca04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "print(r2)\n",
    "adj_r2 = 1-(1-r2)*(len(y_test)-1)/(len(y_test)-1)\n",
    "print(adj_r2)\n",
    "mse_nn = mean_squared_error(y_test, predictions)\n",
    "print(mse_nn**0.5)\n",
    "print(mse_nn)\n",
    "mae_nn = mean_absolute_error(y_test, predictions)\n",
    "print(mae_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97369c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_test))\n",
    "print(np.std(y_test))\n",
    "print(np.var(y_test))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(np.mean(predictions))\n",
    "print(np.std(predictions))\n",
    "print(np.var(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ca5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "idx = [ i for i in range(31142)]\n",
    "plt.scatter(idx, y_test, color='blue', label='Actual')\n",
    "plt.scatter(idx, predictions, color='red', label='Predicted')\n",
    "plt.title('NN')\n",
    "plt.xlabel('Input feature')\n",
    "plt.ylabel('Target variable')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test[:100], color='blue', linestyle = 'dotted')\n",
    "plt.plot(predictions[:100], color='red', linestyle = 'dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
